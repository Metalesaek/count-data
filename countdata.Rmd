---
title: "countdata"
author: "Abdelkader Metales"
date: "1/11/2020"
output:
  pdf_document: default
  html_document: default
---


```{r setup, include=FALSE, warning=FALSE,error=FALSE,message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Introduction:

When we deal with data that has a response variable of integer data, using a linear regression may violate the normality assumptions and hence all the classical statistic tests would fail to evaluate the model. However, as we do with logistic regression models, the generalized linear model **GLM** can also be used here by specifying the suitable distribution.

The suitable distributions for this type of data are **poisson** distribution and **negative binomial** distribution. The former is the best choice if the mean and the variance of the response varaible are closer to each other, but if they are not which gives rise of the **overdispersion** problem of the residuals, then the poisson distribution can not capture these extra dispersion. however, in this case, we can use the latter that does not have this restriction.
  

There is another alternative if neither the poisson distribution nor the negative binomial are suitable called the **Maximum quasi likelihood**. The advantage of this method is that uses only the relationship between the mean and the variance and does not require any  prespesified distribution. Moreover, their estimators are approximately efficient such as the maximum likelihood estimators.


To well understand how to model the count data we are going use **Doctorvisits** data from **AER** package, in which the variable **visits** will be our target variabel, so let's call this data with the packages that we need 


```{r,message=FALSE}
library(tidyverse)
library(AER)
library(broom)
library(performance)
data("DoctorVisits")
doc<-DoctorVisits
glimpse(doc)

```

This data from australian health survey where **visits** is the number of doctor visits in past two week with 11 features listed above.

First we list the summary of the data to get a first glance.

```{r}
summary(doc)
```

As we see we do not have missing values and the visits values ranges from 0 to 9 but it chould be of integer type rather than double. Similarly, the variable **illness** should be converted to factor type since it has a few different values.   

```{r}
doc$visits<-as.integer(doc$visits)
doc$illness<-as.factor(doc$illness)
tab <- table(doc$visits)
tab
```


First we check the correlation bertween each pair of variables.

```{r,message=FALSE}
library(psych)
pairs.panels(doc)

```


First let's compare the empirical distribution of the variable  **visits** and the theoretical poisson distribution with $\lambda$ equals the visits mean `mean(doc$visits)`, and the total number of observations is 5190.

```{r}
pos<-dpois(0:9,0.302)*5190
both<-numeric(20)
both[1:20 %% 2 != 0]<-tab
both[1:20 %% 2 == 0]<-pos
labels<-character(20)
labels[1:20 %% 2==0]<-as.character(0:9)
barplot(both,col=rep(c("red","yellow"),10),names=labels)

```



As we see the two distributions are more or less closer to each other.
Let's now check the negative binomail distribution by first estimate the clumping parameter $k=\frac{\bar x^2}{s^2-\bar x}$.  



```{r}
k<-mean(doc$visits)^2/(var(doc$visits)-mean(doc$visits))
bin<-dnbinom(0:9,0.27,mu=0.302)*5190
both1<-numeric(20)
both1[1:20 %% 2 != 0]<-tab
both1[1:20 %% 2 == 0]<-bin
labels<-character(20)
labels[1:20 %% 2==0]<-as.character(0:9)
barplot(both1,col=rep(c("red","yellow"),10),names=labels)

```

With this distribution it seems that the empiricall distribution is closer to the negative binomail than the poisson distribution.

**Note**: This data has very large number of zeros for the outcome compared to the other values which means that any trained model that does not take into account this anomaly will be biased to predict more likely the **zero** value. However, at the end of this paper I will show two famous models to handel this type of count data called **Haurdle** model and **zero_inflated** model.         


## Data partition

First we split the data between training set and testing set.

```{r}
set.seed(123)
index<-sample(2,nrow(doc),replace = TRUE,p=c(.8,.2))
train<-doc[index==1,]
test<-doc[index==2,]
```



## count data with poisson distribution

In practice this distribution is the first distribution ckecked with count data, since its outcomes are integer numbers. 


```{r}
model1<-glm(visits~., data=train, family ="poisson")
tidy(model1)
```


As we see all the variables are significant except for the income so we remove this variable.


```{r}
model1<-glm(visits~.-income, data=train, family ="poisson")
tidy(model1)
```




let's check the model statistics 


```{r}
glance(model1)
```

since the deviance value 3482.854	 is closer to the degrees of freedom 4139, we do not much worry about **overdisperssion** problem. However, we can use chisq test as follows.

```{r}
pchisq(model1$deviance,model1$df.residual,lower.tail = FALSE)
```


The probablity is almost equal to 1 meaning that we do not have strong evidences to reject the null hypothesis of no overdispersion . 


In case we have overdispersion we can fit another model using the maximum qusai likelihod. Even we do not need to fit another model, let's go ahead and fit this model to show how it differs from the original model.    



```{r}
model2<-glm(visits~.-income, data=train, family ="quasipoisson")
tidy(model2)
```

Since here also all the variables are significant We see that the models are approximately the same except the correction of the standard errors which are now more larger. In other words, the poisson distribution under overdisperssion underestimates the standard errors and hence the t test would be biased towards the rejection of the null hypothesis. 


```{r}
cbind(tidy(model1)[,c(1,2,3)],tidy(model2)[,c(2,3)])
```

Now to test our models we use the testing set **test** by ploting the  original and the predicted values.

```{r}
pred<- predict.glm(model1,newdata=test[test$visits!=0,],type = "response")
plot(test$visits[test$visits!=0],type = "b",col="red")
lines(round(pred),col="blue")
```


From this plot we can say that the model does not fit well the data espacially the larger values that are not well captured, hoawever this may due to the fact that the data are very skewed towards zero.

To compare different models we can use the **root mean-square error** and **mean absolute error**.


```{r,message=FALSE}
library(ModelMetrics)
pred<- predict.glm(model1,newdata=test,type = "response")
rmsemodelp<-rmse(test$visits,round(pred))
maemodelp<-mae(test$visits,round(pred))
rmsemodelp
maemodelp
```


If we treet the outcome as categorical variable we can get the accuracy rate for the confusion matrix as follows.

```{r, message=FALSE}
library(caret)
pred<-round(pred)
pred<-as.factor(pred)
pred1<-fct_expand(pred,c("4","5","6","7","8","9"))
CMmodelp <- confusionMatrix(as.factor(test$visits),as.factor(pred1))
CMmodelp


```

 As we see the accuracy rate is about 79.13%, Let's compare this rate with the model traind with quasi maximum likelihood.          

But before that let's first plot the result

```{r}
predq<- predict.glm(model2,newdata=test[test$visits!=0,],type = "response")
plot(test$visits[test$visits!=0],type = "b",col="red")
lines(round(predq),col="blue")
```


The rmse for this model 

```{r}
predq<- predict.glm(model2,newdata=test,type = "response")
rmsemodelqp<-rmse(test$visits,round(predq))
maemodelqp<-mae(test$visits,round(predq))
maemodelqp
rmsemodelqp
```


And the accuracy rate if we use the confusion matrix.

```{r, message=FALSE}
predq<- predict(model2,newdata=test,type = "response")
predq<-round(predq)
predq<-as.factor(predq)
predq1<-fct_expand(predq,c("5","6","7","8","9"))
CMmodelqp<-confusionMatrix(as.factor(test$visits),as.factor(predq1))
CMmodelqp
```


we get the same rate since the model1 does not have overdispersion problem so the model2 performs approximately by the same way.

### Count data with negative binomial distribution 

The negative binomial distribution is used as an alternative for the poisson distribution under overdispersion problem. 

```{r,message=FALSE}
library(MASS)
model3<-glm.nb(visits~.-income, data=train)
summary(model3)
```

As before we visualize the performance of this model as follows.


```{r}
prednb<- predict.glm(model3,newdata=test[test$visits!=0,],type = "response")
plot(test$visits[test$visits!=0],type = "b",col="red")
lines(round(prednb),col="blue")
```

This plot seems better than the previous ones, so figure out which model is best using rmse. 


```{r}
prednb<- predict.glm(model3,newdata=test,type = "response")
rmsemodelnb<-rmse(test$visits,round(prednb))
maemodelnb<-mae(test$visits,round(prednb))
rmsemodelnb
maemodelnb

```


Comparing this value to that from the poisson model  **0.7381921**, it is clear that the poisson model is the best.  

now let's check the diffrence using the accuracy rate from the confusion matrix.


```{r, message=FALSE}
prednb<- predict.glm(model3,newdata=test,type = "response")
prednb<-round(prednb)
prednb<-as.factor(prednb)
prednb1<-fct_expand(prednb,c("6","7","8","9"))
CMmodelnb<-confusionMatrix(as.factor(test$visits),as.factor(prednb1))
CMmodelnb
```


With the negative binomial we get roughly the same accuracy rate 79.23% such as the poisson model.


## Hurdle model

Originally proposed by Mullahy (1986) this model can take into account the fact that the data has more zeros and also can handle the overdispersion problem. It has two components, truncated count component defined by the chosen discrete distribution such as poisson or negative binomial, and a hurdle components models zero vs larger counts (that uses censored count distribution or binomial model).  For more detail about hurdle and zero inflated models click [here](https://cran.r-project.org/web/packages/pscl/vignettes/countreg.pdf#cite.countreg%3AZeileis%3A2006) 

To perform this model we make use of the function **hurdle** from the package **pscl**. 

### hurdle model with poisson distribution.


```{r,message=FALSE}
library(pscl)
modelhp<-hurdle(visits~. -income, data=train,dist = "poisson")
summary(modelhp)
```

As we did before we plot the result.


```{r}
predhp<- predict(modelhp,newdata=test[test$visits!=0,],type = "response")
plot(test$visits[test$visits!=0],type = "b",col="red")
lines(round(predhp),col="blue")
```

The rmse for this model


```{r}
predhp<- predict(modelhp,newdata=test,type = "response")
rmsemodelhp<-rmse(test$visits,round(predhp))
maemodelhp<-mae(test$visits,round(predhp))
rmsemodelhp
maemodelhp
```


this value is slightly smaller than that of poisson model 0.7381921.

For the accuracy rate we get.


```{r, message=FALSE}
predhp<- predict(modelhp,newdata=test,type = "response")
predhp<-round(predhp)
predhp<-as.factor(predhp)
predhp1<-fct_expand(predhp,c("5","6","7","8","9"))
CMmodelhp<-confusionMatrix(as.factor(test$visits),predhp1)
CMmodelhp

```

This model has the same accuracy as the poisson model. 


### hurdle model with negative binomial distribution.

Now let's try to use the negative binomial instead.


```{r,message=FALSE}
modelhnb<-hurdle(visits~.-income, data=train,dist = "negbin")
summary(modelhnb)
```

The plot of the result. 

```{r}
predhnb<- predict(modelhnb,newdata=test[test$visits!=0,],type = "response")
plot(test$visits[test$visits!=0],type = "b",col="red")
lines(round(predhnb),col="blue")
```

The rmse for this model


```{r}
predhnb<- predict(modelhnb,newdata=test,type = "response")
rmsemodelhnb<-rmse(test$visits,round(predhnb))
maemodelhnb<-mae(test$visits,round(predhnb))
rmsemodelhnb
maemodelhnb
```

This model has a slight larger value for rmse but this difference can be insignificant and with other testing set it can be better.

let's use the testing set to get the confusion matrix for this model.


```{r, message=FALSE}
predhnb<- predict(modelhnb,newdata=test,type = "response")
predhnb<-round(predhnb)
predhnb<-as.factor(predhnb)
levels(predhnb)
predhnb<-fct_expand(predhnb,c("5","6","7","8","9"))
CMmodelhnb<-confusionMatrix(as.factor(test$visits),as.factor(predhnb))
CMmodelhnb
```

As we see the accuracy rates for these models are the same. 



## Zero inflated model

Such as the previous model type , this model also combines two components a point mass at zero and a count distribution such as poisson and negative binomial distribution (or geometric).

### Zero inflated model with poisson distribution

Here also we fit tow models one with poisson and one with negative binomial

```{r}
modelzp<-zeroinfl(visits~.-income, data=train,dist = "poisson")
summary(modelzp)
```


```{r}
predzp<- predict(modelzp,newdata=test[test$visits!=0,],type = "response")
plot(test$visits[test$visits!=0],type = "b",col="red")
lines(round(predzp),col="blue")
```


```{r}
predzp<- predict(modelzp,newdata=test,type = "response")
rmsemodelzp<-rmse(test$visits,round(predzp))
maemodelzp<-mae(test$visits,round(predzp))
rmsemodelzp
maemodelzp
```

```{r, message=FALSE}
predzp<- predict(modelzp,newdata=test,type = "response")
predzp<-round(predzp)
predzp<-as.factor(predzp)
predzp1<-fct_expand(predzp,c("4","5","6","7","8","9"))
CMmodelzp<-confusionMatrix(as.factor(test$visits),as.factor(predzp1))
CMmodelzp
```


### Zero inflated model with negative binomial distribution

```{r}
modelznb<-zeroinfl(visits~., data=train,dist = "negbin")
summary(modelznb)
```


```{r}
predznb<- predict(modelznb,newdata=test,type = "response")
rmsemodelznb<-rmse(test$visits,round(predznb))
maemodelznb<-mae(test$visits,round(predznb))
rmsemodelznb
maemodelznb
```

```{r}
predznb<-round(predznb)
predznb<-as.factor(predznb)
predznb1<-fct_expand(predznb,c("4","5","6","7","8","9"))
CMmodelznb<-confusionMatrix(as.factor(test$visits),as.factor(predznb1))
CMmodelznb


```



Finally let's compare these different models.

```{r}
accuracy_rate <- c(CMmodelp$overall[[1]],CMmodelqp$overall[[1]],
            CMmodelnb$overall[[1]],CMmodelhp$overall[[1]],
            CMmodelhnb$overall[[1]],CMmodelzp$overall[[1]],
            CMmodelznb$overall[[1]])
rmse<-c(rmsemodelp,rmsemodelqp,rmsemodelnb,rmsemodelhp,rmsemodelhnb,
           rmsemodelzp,rmsemodelznb)
mae<-c(maemodelp,maemodelqp,maemodelnb,maemodelhp,maemodelhnb,
           maemodelzp,maemodelznb)
models<-c("pois","qpois","nb","hpois","hnb","zerpois","zernb")

df<-data.frame(models,accuracy_rate,rmse,mae)
df
```


All the above metrics have chosen the zero inflated negative binomial model as the best model  with accuracy rate about **79.9%**, minimum rmse value **0.7309579**, and minimum mae value **0.2753623**. this result is in line with the fact that this kind of models take care of the zero inflated data.  
